!pip install pandas scikit-learn -q  # 静默安装

import pandas as pd
from sklearn.model_selection import train_test_split

# 加载数据（文件路径需与上传位置一致）
df = pd.read_csv('/content/training.1600000.processed.noemoticon.csv', 
                 encoding='ISO-8859-1', 
                 header=None,
                 names=['target','id','date','flag','user','text'])

# 数据清洗
df = df[['text','target']]
df['target'] = df['target'].replace({4:1})  # 负面=0, 正面=1

# 分层抽样（确保正负样本各500条）
df_sample, _ = train_test_split(
    df, 
    train_size=1000, 
    stratify=df['target'],  # 关键！保持比例
    random_state=42
)

# 验证抽样结果
print("负面样本数:", len(df_sample[df_sample['target']==0]))
print("正面样本数:", len(df_sample[df_sample['target']==1]))
print("\n负面示例:", df_sample[df_sample['target']==0]['text'].iloc[0])
print("正面示例:", df_sample[df_sample['target']==1]['text'].iloc[0])

# 保存抽样数据
df_sample.to_csv("/content/Day1_Sentiment/sampled_data.csv", index=False)

!pip install transformers datasets -q

import os
os.environ["WANDB_DISABLED"] = "true"  # 禁用wandb

from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from datasets import Dataset

# 加载预训练模型
model_name = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)

# 数据预处理函数
def preprocess_function(examples):
    tokenized_inputs = tokenizer(
        examples["text"], 
        truncation=True, 
        padding="max_length", 
        max_length=128  # 控制序列长度
    )
    tokenized_inputs["labels"] = examples["target"]
    return tokenized_inputs

# 转换数据格式
dataset = Dataset.from_pandas(df_sample)
tokenized_dataset = dataset.map(
    preprocess_function,
    batched=True,
    remove_columns=["text", "target"]  # 清理冗余字段
)

# 拆分数据集
split_dataset = tokenized_dataset.train_test_split(test_size=0.2)
train_dataset = split_dataset["train"]
test_dataset = split_dataset["test"]

# 训练参数配置
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    num_train_epochs=1,
    per_device_train_batch_size=16,
    logging_steps=10,  # 每10步记录一次loss
    learning_rate=2e-5,  # 合理学习率
    save_strategy="no"   # 关闭自动保存以加速
)

# 初始化训练器
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)

# 开始训练
train_history = trainer.train()

import numpy as np
from sklearn.metrics import accuracy_score, confusion_matrix

# 预测测试集
predictions = trainer.predict(test_dataset)
pred_labels = np.argmax(predictions.predictions, axis=1)
true_labels = test_dataset["labels"]

# 计算指标
accuracy = accuracy_score(true_labels, pred_labels)
cm = confusion_matrix(true_labels, pred_labels)

print(f"测试集准确率: {accuracy:.2%}")
print("混淆矩阵:\n", cm)

# 保存评估结果
with open("/content/Day1_Sentiment/evaluation.txt", "w") as f:
    f.write(f"Accuracy: {accuracy}\nConfusion Matrix:\n{cm}")
  
